# This workflow identifies changes between the base and the head ref, for use in
# other workflows to decide if they should be executed.

name: Identify Changes

on:
  workflow_call:
    # These inputs allow the filter action to be able to access the correct refs for
    # comparison in changes detection, it is required as this is called from the
    # merge_group context.
    inputs:
      base_ref:
        required: true
        type: string
      head_ref:
        required: true
        type: string
      int_tests:
        required: false
        type: boolean
        default: false
      source:
        required: false
        type: boolean
        default: true
    outputs:
      source:
        value: ${{ jobs.changes.outputs.source }}
      dependencies:
        value: ${{ jobs.changes.outputs.dependencies }}
      internal_events:
        value: ${{ jobs.changes.outputs.internal_events }}
      cue:
        value: ${{ jobs.changes.outputs.cue }}
      component_docs:
        value: ${{ jobs.changes.outputs.component_docs }}
      markdown:
        value: ${{ jobs.changes.outputs.markdown }}
      install:
        value: ${{ jobs.changes.outputs.install }}
      k8s:
        value: ${{ jobs.changes.outputs.k8s }}
      all-int:
        value: ${{ jobs.change_int_tests.outputs.all-int }}
      amqp:
        value: ${{ jobs.change_int_tests.outputs.amqp }}
      appsignal:
        value: ${{ jobs.change_int_tests.outputs.appsignal }}
      aws:
        value: ${{ jobs.change_int_tests.outputs.aws }}
      axiom:
        value: ${{ jobs.change_int_tests.outputs.axiom }}
      azure:
        value: ${{ jobs.change_int_tests.outputs.azure }}
      clickhouse:
        value: ${{ jobs.change_int_tests.outputs.clickhouse }}
      databend:
        value: ${{ jobs.change_int_tests.outputs.databend }}
      datadog:
        value: ${{ jobs.change_int_tests.outputs.datadog }}
      dnstap:
        value: ${{ jobs.change_int_tests.outputs.dnstap }}
      docker-logs:
        value: ${{ jobs.change_int_tests.outputs.docker-logs }}
      elasticsearch:
        value: ${{ jobs.change_int_tests.outputs.elasticsearch }}
      eventsoredb:
        value: ${{ jobs.change_int_tests.outputs.eventsoredb }}
      fluent:
        value: ${{ jobs.change_int_tests.outputs.fluent }}
      gcp:
        value: ${{ jobs.change_int_tests.outputs.gcp }}
      humio:
        value: ${{ jobs.change_int_tests.outputs.humio }}
      http-client:
        value: ${{ jobs.change_int_tests.outputs.http-client }}
      influxdb:
        value: ${{ jobs.change_int_tests.outputs.influxdb }}
      kafka:
        value: ${{ jobs.change_int_tests.outputs.kafka }}
      logstash:
        value: ${{ jobs.change_int_tests.outputs.logstash }}
      loki:
        value: ${{ jobs.change_int_tests.outputs.loki }}
      mongodb:
        value: ${{ jobs.change_int_tests.outputs.mongodb }}
      nats:
        value: ${{ jobs.change_int_tests.outputs.nats }}
      nginx:
        value: ${{ jobs.change_int_tests.outputs.nginx }}
      opentelemetry:
        value: ${{ jobs.change_int_tests.outputs.opentelemetry }}
      postgres:
        value: ${{ jobs.change_int_tests.outputs.postgres }}
      prometheus:
        value: ${{ jobs.change_int_tests.outputs.prometheus }}
      pulsar:
        value: ${{ jobs.change_int_tests.outputs.pulsar }}
      redis:
        value: ${{ jobs.change_int_tests.outputs.redis }}
      splunk:
        value: ${{ jobs.change_int_tests.outputs.splunk }}
      webhdfs:
        value: ${{ jobs.change_int_tests.outputs.webhdfs }}

  changes:
    runs-on: ubuntu-20.04
    if: ${{ inputs.source }}
    # Set job outputs to values from filter step
    outputs:
      # General source code
      source: ${{ steps.filter.outputs.source }}
      dependencies: ${{ steps.filter.outputs.dependencies }}
      internal_events: ${{ steps.filter.outputs.internal_events }}
      cue: ${{ steps.filter.outputs.cue }}
      component_docs: ${{ steps.filter.outputs.component_docs }}
      markdown: ${{ steps.filter.outputs.markdown }}
      install: ${{ steps.filter.outputs.install }}
      # K8s
      k8s: ${{ steps.filter.outputs.k8s }}
    steps:
    - uses: actions/checkout@v3

    - uses: dorny/paths-filter@v2
      id: filter
      with:
        base: ${{ inputs.base_ref }}
        ref: ${{ inputs.head_ref }}
        # TODO check if worth keying off the other internal components that the k8s tests utilize, suspect not.
        filters: |
          source:
            - ".github/workflows/test.yml"
            - ".cargo/**"
            - "benches/**"
            - "lib/**"
            - "proto/**"
            - "scripts/**"
            - "src/**"
            - "tests/**"
            - "build.rs"
            - "Cargo.lock"
            - "Cargo.toml"
            - "Makefile"
            - "rust-toolchain.toml"
            - "vdev/**"
          deny:
            - 'deny.toml'
            - "vdev/**"
          dependencies:
            - ".cargo/**"
            - 'Cargo.toml'
            - 'Cargo.lock'
            - 'rust-toolchain.toml'
            - '.github/workflows/pr.yml'
            - 'Makefile'
            - 'scripts/cross/**'
            - "vdev/**"
          cue:
            - 'website/cue/**'
            - "vdev"
          component_docs:
            - 'scripts/generate-component-docs.rb'
            - "vdev/**"
          markdown:
            - '**/**.md'
            - "vdev/**"
          internal_events:
            - 'src/internal_events/**'
            - "vdev/**"
          docker:
            - 'distribution/docker/**'
            - "vdev/**"
          install:
            - ".github/workflows/install-sh.yml"
            - "distribution/install.sh"
          k8s:
            - "src/sources/kubernetes_logs/**"

  changes_int_tests:
    runs-on: ubuntu-latest
    if: ${{ inputs.int_tests }}
    outputs:
      amqp: ${{ steps.filter.outputs.amqp }}
      appsignal: ${{ steps.filter.outputs.appsignal}}
      aws: ${{ steps.filter.outputs.aws }}
      axiom: ${{ steps.filter.outputs.axiom }}
      azure: ${{ steps.filter.outputs.azure }}
      clickhouse: ${{ steps.filter.outputs.clickhouse }}
      databend: ${{ steps.filter.outputs.databend }}
      datadog: ${{ steps.filter.outputs.datadog }}
      dnstap: ${{ steps.filter.outputs.dnstap }}
      docker-logs: ${{ steps.filter.outputs.docker-logs }}
      elasticsearch: ${{ steps.filter.outputs.elasticsearch }}
      evenstoredb: ${{ steps.filter.outputs.evenstoredb }}
      fluent: ${{ steps.filter.outputs.fluent }}
      gcp: ${{ steps.filter.outputs.gcp }}
      humio: ${{ steps.filter.outputs.humio }}
      http-client: ${{ steps.filter.outputs.http-client }}
      influxdb: ${{ steps.filter.outputs.influxdb }}
      kafka: ${{ steps.filter.outputs.kafka }}
      logstash: ${{ steps.filter.outputs.logstash }}
      loki: ${{ steps.filter.outputs.loki }}
      mongodb: ${{ steps.filter.outputs.mongodb }}
      nats: ${{ steps.filter.outputs.nats }}
      nginx: ${{ steps.filter.outputs.nginx }}
      opentelemetry: ${{ steps.filter.outputs.opentelemetry }}
      postgres: ${{ steps.filter.outputs.postgres }}
      prometheus: ${{ steps.filter.outputs.prometheus }}
      pulsar: ${{ steps.filter.outputs.pulsar }}
      redis: ${{ steps.filter.outputs.redis }}
      splunk: ${{ steps.filter.outputs.splunk }}
      webhdfs: ${{ steps.filter.outputs.webhdfs }}
    steps:
      - uses: actions/checkout@v3

      - run: |
          INTEGRATIONS="amqp
          appsignal
          aws
          axiom
          azure
          clickhouse
          databend
          datadog
          dnstap
          docker-logs
          elasticsearch
          eventstoredb
          fluent
          gcp
          humio
          http-client
          influxdb
          kafka
          logstash
          loki
          mongodb
          nats
          nginx
          opentelemetry
          postgres
          prometheus
          pulsar
          redis
          splunk
          webhdfs"

          echo 'all-int:' > int_test_filters.yaml
          echo '- "lib/vector-core/**"' >> int_test_filters.yaml

          for integration in ${INTEGRATIONS} ; do
            echo '${integration}:' > int_test_filters.yaml
            PATHS=$(cargo vdev int paths ${integration})
            while IFS= read -r path ; do echo '- ${path}' >> int_test_filters.yaml ; done <<< "$PATHS"
          done

      - uses: dorny/paths-filter@v2
        id: filter
        with:
          base: ${{ inputs.base_ref }}
          ref: ${{ inputs.head_ref }}
          filters: int_test_filters.yaml
